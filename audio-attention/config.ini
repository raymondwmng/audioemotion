[DEFAULT]
### ----------------------------------------- ENV
DEBUG_MODE=false
WDIR=/share/spandh.ami1/emo/dev/6class/vlog/mosei/tools/audioemotion/audio-attention/exp/
exp=none
path=none
model_name=none
### ----------------------------------------- PYTORCH
USE_CUDA=true
### ----------------------------------------- TRAINING SETUP 
MAX_ITER=100
BATCHSIZE=1
VALIDATION=false
### ----------------------------------------- MODEL
SAVE_MODEL=true
SAVE_ITER=1
USE_PRETRAINED=true
SELECT_BEST_MODEL=false
### ----------------------------------------- FEATURES
EXT=fbk
### ----------------------------------------- OPTIMIZER
OPTIM=Adam
### ----------------------------------------- LEARNING RATE
LEARNING_RATE=0.0001
LR_schedule=ReduceLROnPlateau
LR_size=1
LR_factor=0.1
### ----------------------------------------- MULTI CRITERIONS
MULTILOSS=false
### ----------------------------------------- ENCODER
input_size=23
hidden_size=512
num_layers=2
outlayer_size=1024
### ----------------------------------------- ATTENTION
att_hidden_size=128
dan_hidden_size=1024
ATTENTION=true
multihead_size=8
### ----------------------------------------- PREDICTOR
num_emotions=6
num_emo_layers=1
num_domains=4
num_dom_layers=1
### ----------------------------------------- DAT
DAT=false
c=0.1
# Salil: I am finding that setting lambda to lower values (range of 0.01 to 0.07) leads to the best results with Domain Adversarial Training whereas lambda values in the range of 0.1 to 0.3 leads to best results for Multi-Task learning.
TASK=none 
#EMO+DOM
### ----------------------------------------- PRIORS
PRIORS=false
### ----------------------------------------- OOD-adapt
adapt=none

